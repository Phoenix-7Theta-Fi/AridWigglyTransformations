{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMeaXyHYkrv1KXMYeVGjD6A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Phoenix-7Theta-Fi/AridWigglyTransformations/blob/main/2nd_October.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "By_dWE0HSeDP"
      },
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "!pip install langchain\n",
        "!pip install langchain-community\n",
        "!pip install -q langchain-google-genai langchain-qdrant qdrant-client\n",
        "!pip install protobuf==3.20.3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Required imports\n",
        "from langchain_google_genai import GoogleGenerativeAI\n",
        "import os\n",
        "import getpass\n",
        "\n",
        "# Set the Google API key\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = \"qwertyuiop\"\n",
        "\n",
        "# Initialize Google Generative AI (Gemini 1.5 Pro) for both Triage and Diagnostic agents\n",
        "triage_agent = GoogleGenerativeAI(model=\"gemini-1.5-pro\", google_api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
        "diagnostic_agent = GoogleGenerativeAI(model=\"gemini-1.5-pro\", google_api_key=os.environ[\"GOOGLE_API_KEY\"])\n"
      ],
      "metadata": {
        "id": "WU627AaKTXik"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Required imports for Qdrant and Google embeddings\n",
        "from qdrant_client import QdrantClient\n",
        "from langchain_qdrant import QdrantVectorStore\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "import os\n",
        "\n",
        "# Set the Google API key and Qdrant API key directly from the provided credentials\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"qwertyuiop\"  # Provided Google API key\n",
        "\n",
        "QDRANT_API_KEY = \"abcdefghi\"\n",
        "QDRANT_URL = \"abcdefg.com\"  # Provided Qdrant URL\n",
        "\n",
        "# Initialize Qdrant client using the cloud URL and API key\n",
        "client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)\n",
        "\n",
        "# Initialize Google Generative AI Embeddings model for vectorization\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "\n",
        "# Use the existing \"ayurveda_collection\" in Qdrant\n",
        "vector_store = QdrantVectorStore(\n",
        "    client=client,\n",
        "    collection_name=\"ayurveda_collection\",  # Provided collection name\n",
        "    embedding=embeddings,  # Embedding model for semantic search\n",
        ")\n"
      ],
      "metadata": {
        "id": "4jtE5hpSUuJe"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "# Initialize conversation buffer for managing consultation context\n",
        "conversation_memory = ConversationBufferMemory()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfocpCZmVh_G",
        "outputId": "50c7f04d-ca5c-49ef-e776-a88d6353d95b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-62dd46c0a1dd>:4: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  conversation_memory = ConversationBufferMemory()\n"
          ]
        }
      ]
    }
  ]
}